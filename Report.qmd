---
title: "Report"
author: "Justin Powley"
format: html
editor: visual
---

```{r, init, message = F, warning = F, error = F}
library(tidyquant)
library(tidyverse)
library(RTL)
library(tsibble)
library(feasts)
library(slider)
library(httr)
library(curl)
library(zoo)
library(forecast)
library(corrplot)
library(broom)
library(car)
library(ggfortify)

# Note that sometimes the lack of an API sometimes necessitates loading from excel worksheets.
# This is not the equivalent of modeling in excel, it's instead just another mechanism for us to load data automatically into the model.
library(xlsx)

EIA_API <- "UKCNbCB0m8aixfPBshQU3Jdlz2uZsEbG2HebvhHX"
```

```{r, data_import}
# Yahoo Finance
tickers <- c("RB=F", "HO=F", "CL=F", "NG=F")
start_date <- '2018-01-01'
price_data_in <- tq_get(tickers, get = "stock.prices", from = start_date) %>% 
  dplyr::mutate(symbol = case_when(symbol == tickers[1] ~ "RBOB",
                                   symbol == tickers[2] ~ "Heating_Oil",
                                   symbol == tickers[3] ~ "WTI",
                                   symbol == tickers[4] ~ "Natural_Gas"))

eia_tickers <- tribble(~ticker, ~name, "PET.WTTSTUS1.W", "US_Crude_Inventory",
                       "PET.MCRFPUS1.M", "US_Crude_Prod",
                       "NG.NW2_EPG0_SWO_R48_BCF.W", "Lower48NGStorage",
                       "PET.WCRNTUS2.W", "US_Crude_NI",
                       "PET.WRPNTUS2.W", "US_Petrol_Products_NI",
                       "PET.WGFRPUS2.W", "US_Gasoline_Production",
                       "PET.MGFSTUS1.M", "US_Gasoline_Stocks_Blended",
                       "PET.M_EPOBGRR_SAE_NUS_MBBL.M", "US_RBOB_Stocks_Unblended",
                       "PET.MO5ST_NUS_1.M", "US_Conventional_Stocks_Unblended",
                       "PET.WPULEUS3.W", "Pct_Operable_Utilization"
                       )

EIA_Data <- eia2tidy_all(eia_tickers, EIA_API)
EIA_Data %>% group_by(series) %>% dplyr::mutate(temp = 1, temp = cumsum(temp)) %>% 
  dplyr::filter(temp == 1) %>% 
  dplyr::select(-temp)

fred_tickers <- c("IPMINE", "GDP", "TRUCKD11")
fred_data <- tq_get(fred_tickers, get = "economic.data", from = start_date) %>% 
  dplyr::mutate(symbol = case_when(symbol == fred_tickers[1] ~ "Mining_Production_Index",
                                   symbol == fred_tickers[2] ~ "US_GDP",
                                   symbol == fred_tickers[3] ~ "Truck_Tonnage_Index")) %>% 
  dplyr::rename(series = symbol, value = price)

# I'd recommend incorporating Baltic Dry Index (BDI) for shipping by sea. Unfortunately these are metrics which require subscriptions, and as a result aren't included in this report.
```

```{r, preprocessing}
add_ret_metrics <- function(df_in){
  # Accepts a df with columns value, series, date
  # Adds returns and cumulative return metrics for value.
  df_in %>% 
    group_by(series) %>% 
    arrange(series, date) %>% 
    dplyr::mutate(ret_pct = (value-lag(value))/lag(value),
                  ret_log = log(value/lag(value))) %>% 
    tidyr::drop_na() %>% 
    dplyr::mutate(cret_pct = cumprod(ret_pct+1),
                  cret_log = cumsum(ret_log),
                  year_month = yearmonth(date)) %>% 
    return()
}

price_data <- price_data_in %>% 
  dplyr::select(date, series = symbol, value = close, volume)
# rm(price_data_in)

fundamentals_data <- EIA_Data %>% 
  add_ret_metrics()
# rm(EIA_Data)

# 3:2:1 Crack Spread used here. Setting below can be used to adjust the crack spread to other ratios, such as 5:3:2
spread_ratio <- c(3,2,1)

spread_data <- price_data %>% 
  pivot_wider(names_from = series, id_cols = date, values_from = value) %>% 
  dplyr::mutate(Crack_Spread = ((spread_ratio[2]*42*RBOB + 
                                spread_ratio[3]*42*Heating_Oil) - 
                                WTI*spread_ratio[1])/
                                spread_ratio[1])

price_data <- spread_data %>% dplyr::select(date, value = Crack_Spread) %>% 
  dplyr::mutate(series = "Crack_Spread", volume = 0) %>% 
  bind_rows(price_data) %>% 
  add_ret_metrics()


EIA_Data %>% pivot_wider(names_from = series, id_cols = date, values_from = value) %>% 
  dplyr::arrange(desc(date))

fred_data <- fred_data %>% add_ret_metrics()
```

```{r, eda}
# Rolling Correlation of RBOB and WTI
spread_data %>% 
  dplyr::mutate(static_cor = cor(WTI,RBOB),
                cor20 = slide2_dbl(RBOB, WTI, cor, .before = 20, .complete = TRUE),
                cor50 = slide2_dbl(RBOB, WTI, cor, .before = 50, .complete = TRUE),
                cor200 = slide2_dbl(RBOB, WTI, cor, .before = 200, .complete = TRUE)
                ) %>% 
  tidyr::drop_na() %>% 
  ggplot() +
  geom_line(aes(x=date, y = cor20, color = "20-Day Corr")) +
  geom_line(aes(x=date, y = cor50, color = "50-Day Corr")) +
  geom_line(aes(x=date, y = cor200, color = "200-Day Corr")) +
  geom_line(aes(x = date, y = static_cor, color = "Static Corr, Full Horizon")) +
  labs(title = "Rolling Correlations, WTI and RBOB",
       subtitle = "How coupled are spreads to the underlying price?",
       x = "Date",
       y = "Correlation",
       color = "Legend") +
  scale_color_manual(values = c("20-Day Corr" = "red", "50-Day Corr" = "blue", "200-Day Corr" = "green", "Static Corr, Full Horizon" = "black"))

# Natural Gas and Spread Price
spread_data %>% 
  ggplot() +
  geom_line(aes(x = date, y = Crack_Spread), color = "red") +
  geom_line(aes(x = date, y = Natural_Gas), color = "black")

# Crude Stocks
fundamentals_data %>% 
  dplyr::filter(series == "US_Crude_Inventory" & date > start_date) %>% 
  ggplot() +
  geom_line(aes(x = date, y = value)) +
  labs(title = "US Crude Stocks", y = "Thousands of Barrels", x = "Date")

# Crude Stocks, PCT Change
fundamentals_data %>% 
  dplyr::filter(series == "US_Crude_Inventory" & date > start_date) %>% 
  ggplot() +
  geom_line(aes(x = date, y = ret_pct)) +
  labs(title = "US Crude Stocks, Changes in Supply", y = "% Change in Supply", x = "Date")

# Plant Utilization versus Crude Inventories
fundamentals_data %>% 
  pivot_wider(names_from = series, id_cols = date, values_from = value) %>% 
  dplyr::select(Pct_Operable_Utilization, US_Crude_Inventory) %>% 
  tidyr::drop_na() %>% 
  cor()

# This graph reveals short term supply/demand shocks as well as a general inflationary pressure which leads to a gradual increase over the course of the time period.
price_data %>% 
  dplyr::filter(series == "RBOB") %>% 
  ggplot() +
  geom_line(aes(x = date, y = value))
```

```{r, Risk}
price_data %>% 
  dplyr::filter(series == "Crack_Spread" | series == "RBOB" | series == "WTI" | series == "Heating_Oil") %>% 
  dplyr::mutate(series = case_when(series == "Crack_Spread" ~ "Crack Spread",
                                   series == "RBOB" ~ "RBOB",
                                   series == "WTI" ~ "WTI",
                                   TRUE ~ "Heating Oil")) %>% 
  dplyr::filter(ret_pct <= 1, ret_pct >= -1) %>% 
  ggplot() +
  geom_histogram(aes(x = ret_pct, y = ..count../sum(..count..)), bins = 100) +
  labs(x = "Percent Return, Daily", y = "Density", title = "Crack Spread Volatility Compared to its Market Dependencies") +
  facet_grid(series~.)

price_data %>% 
  dplyr::filter(series == "Crack_Spread" | series == "RBOB") %>% 
  dplyr::mutate(series = case_when(series == "Crack_Spread" ~ "Crack Spread",
                                   series == "RBOB" ~ "RBOB",
                                   series == "WTI" ~ "WTI",
                                   TRUE ~ "Heating Oil")) %>% 
  dplyr::filter(ret_pct <= 1, ret_pct >= -1) %>% 
  ggplot() +
  geom_histogram(aes(x = ret_pct, y = ..count../sum(..count..)), bins = 100) +
  labs(x = "Percent Return, Daily", y = "Density", title = "Crack Spread Versus Gasoline Volatility") +
  facet_grid(series~.)

# price_data %>% pivot_wider(id_cols = date, names_from = series, values_from = value) %>% 

price_data %>% 
  group_by(series) %>% 
  dplyr::summarise(
    `Average Return` = mean(ret_pct),
    `Standard Deviation` = sd(ret_pct),
    .groups = "keep")
```

```{r, FHWA}
# Pulling distance traveled estimates from FHWA
# https://www.fhwa.dot.gov/policyinformation/travel_monitoring/tvt.cfm
# Potential to create a fully automated workflow. For now, manually link the reports for the time period of interest.

# Must be newest to oldest
links <- c(FHWA2024 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/24juntvt/24juntvt.xlsx",
           FHWA2023 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/23dectvt/23dectvt.xlsx",
           FHWA2022 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/22dectvt/22dectvt.xlsx",
           FHWA2021 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/21dectvt/21dectvt.xlsx",
           FHWA2020 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/20dectvt/20dectvt.xls",
           FHWA2019 = "https://www.fhwa.dot.gov/policyinformation/travel_monitoring/19dectvt/19dectvt.xls")

month_tags <- c("JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC")

clean_FHWA <- function(df_in){
  
  df_in_year <- paste(df_in %>% head(1), collapse = " ") %>% str_extract(pattern = "[0-9][0-9][0-9][0-9]")
  
  df_in %>% 
    tail(1) %>% 
    pivot_longer(names_to = "month", cols = month_tags) %>% 
    dplyr::select(month, value) %>% 
    dplyr::mutate(year = df_in_year) %>% 
    drop_na() %>% 
    return()
}

for(i in 1:length(links)){
  path <- paste0(names(links)[i],".xlsx")
  curl_download(links[i], path)

  # I am hesitant to use specific row indexes here, due to issues which can arise if the template changes. In   a full implementation I'd add checks for keywords in certain rows.cells to ensure that necessary updates and   mismatches aren't missed.
  
  df1 <- xlsx::read.xlsx(path, sheetName = "Page 3", rowIndex = c(3,4,12))
  df2 <- xlsx::read.xlsx(path, sheetName = "Page 3", rowIndex = c(3,13,20))

  if(i == 1){
    FHWA_Data <- df2 %>% clean_FHWA()
  }
  FHWA_Data <- bind_rows(df1 %>% clean_FHWA(), FHWA_Data)
}

FHWA_Data <- FHWA_Data %>% 
  dplyr::mutate(date = yearmonth(paste(month, year)),
                series = "B_Miles_Driven") %>% 
  dplyr::select(series, date, value) %>% 
  dplyr::mutate(date = as.Date(date),
                value = as.numeric(value)) %>% 
  add_ret_metrics()
  
# This uncovers for us some of the seasonal demand for fuel.
FHWA_Data %>% 
  arrange(date) %>% 
  ggplot() +
  geom_line(aes(x = date, y = value)) +
  labs(title = "Seasonal patterns in road travel, using FHWA Data",
       x = "Date", y = "Billions of Miles Traveled")
```

```{r, more eda}
# Re-visualizing data every time I wanted to add another data source was getting inefficient;
# Created a generalized line graph function
s_graph <- function(data, series_name, start_date_in = start_date){
  data %>% 
    dplyr::filter(series == series_name) %>% 
    dplyr::filter(date >= start_date_in) %>% 
    ggplot() +
    geom_line(aes(y = value, x = date)) + 
    labs(title = series_name) %>% 
    return()
}

# Fred
for(s in fred_data$series %>% unique()){
 s_graph(fred_data, s) %>% print()
}

# Price Data
for(s in price_data$series %>% unique()){
 s_graph(price_data, s) %>% print()
}

# Fundamentals Data, EIA
for(s in fundamentals_data$series %>% unique()){
 s_graph(fundamentals_data, s) %>% print()
}

# Notes: Some indicators here track with GDP (Note the strong uptrend. To incorporate these, we may consider normalizing each index to start at 1, and then net the difference between GDP and the other indicator, making a spread)
```

```{r, aggregation, model_prep}
# Note data misalignment. Reports may publish on non-trading days and therefore we need to approximate lining up time periods. For now, we will use the weekly close, and then match the week a report releases on.

year_week_conversion <- function(df_in){
  df_in %>% 
    dplyr::mutate(year_week = paste0(year(date),"-",week(date) %>% sprintf("%02d", .))) %>% 
    arrange(series, date) %>% 
    group_by(series, year_week) %>% 
    dplyr::mutate(temp = 1, temp = cumsum(temp)) %>% 
    dplyr::filter(temp == max(temp)) %>% 
    return()
}

aggregate <- price_data %>% year_week_conversion()

aggregate <- fundamentals_data %>% year_week_conversion() %>% bind_rows(aggregate)

aggregate <- fred_data %>% year_week_conversion() %>% bind_rows(aggregate)

aggregate <- FHWA_Data %>% year_week_conversion() %>% bind_rows(aggregate)  

wide_agg <- aggregate %>% 
  dplyr::filter(date >= start_date) %>% 
  pivot_wider(id_cols = year_week, names_from = "series", values_from = value) %>% 
  arrange(year_week)

# Creates a re-key using the last date matching a year-week
date_key <- price_data %>% 
  year_week_conversion() %>% 
  ungroup() %>% 
  dplyr::select(date, year_week) %>% 
  arrange(date) %>% 
  group_by(year_week) %>% 
  dplyr::mutate(temp = 1, temp = cumsum(temp)) %>% 
  dplyr::filter(temp == max(temp)) %>% 
  dplyr::select(-temp)

wide_agg <- wide_agg %>% left_join(date_key, by = "year_week")

# Interpolation, Leaving non-updated values the same as previous.
# Opted for linear interpolation due to a lack of high frequency data. Later, we will conduct additional decomposition and ARIMA models for those which exhibit more structured behavior.

# Interpolated
wide_agg %>% 
  ungroup() %>% 
  dplyr::mutate(B_Miles_Driven = na.interp(B_Miles_Driven),
                Mining_Production_Index = na.interp(Mining_Production_Index),
                Truck_Tonnage_Index = na.interp(Truck_Tonnage_Index),
                US_GDP = na.interp(US_GDP),
                US_Conventional_Stocks_Unblended = na.interp(US_Conventional_Stocks_Unblended),
                US_Crude_Prod = na.interp(US_Crude_Prod),
                US_Gasoline_Stocks_Blended = na.interp(US_Gasoline_Stocks_Blended),
                US_RBOB_Stocks_Unblended = na.interp(US_RBOB_Stocks_Unblended)
                ) %>% 
  dplyr::select(-date, -year_week, -Heating_Oil, - WTI, -RBOB, -Lower48NGStorage, - Natural_Gas) %>% 
  drop_na() %>% 
  cor() %>% 
  # Credit to ChatGPT for improved formatting on this CorrPlot
  corrplot( 
         method = "color",
         col = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200),
         type = "upper",
         order = "hclust",
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 45,
         diag = FALSE,
         number.cex = 0.6,
         addshade = "positive",
         cl.lim = c(-1, 1),
         mar = c(0, 0, 1, 0)
)

# Non Interpolated
uninterpolated_data_w_date <- wide_agg %>% 
  ungroup() %>% 
  dplyr::select(-year_week, -Heating_Oil, - WTI, -RBOB, -Lower48NGStorage, - Natural_Gas, - US_GDP) %>%
  drop_na() %>% 
  dplyr::mutate(t = 1, t = cumsum(t))

uninterpolated_data <- uninterpolated_data_w_date %>% dplyr::select(-date, -t)

uninterpolated_data %>% 
  cor() %>% 
  corrplot( 
         method = "color",
         col = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200),
         type = "upper",
         order = "hclust",
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 45,
         diag = FALSE,
         number.cex = 0.6,
         addshade = "positive",
         cl.lim = c(-1, 1),
         mar = c(0, 0, 1, 0)
)

uninterpolated_data
```

```{r, demonstrational_graphics}
fred_data %>% dplyr::filter(series == "Truck_Tonnage_Index") %>% 
  dplyr::mutate(ret_pct = ret_pct * 10,
                cret_pct = cumprod(1+ret_pct),
                cret_pct = (cret_pct+1)*5-5) %>% 
  bind_rows(price_data %>% dplyr::filter(series == "Crack_Spread" | series == "Heating_Oil")) %>% 
  dplyr::filter(date > "2021-01-01") %>% 
  ggplot() +
  geom_line(aes(x = date, y = cret_pct, color = series)) +
  facet_grid(series~.) +
  labs(y = "Index, Range Adjusted",
       title = "Truck Tonnage Influence on Crack Spreads & Heating Oil",
       x = "Date")

wide_agg %>% 
  ungroup() %>% 
  drop_na() %>% 
  dplyr::select(Truck_Tonnage_Index, Crack_Spread, Heating_Oil) %>% 
  cor()
```

```{r, lm1}
lm1 <- uninterpolated_data %>% lm(Crack_Spread ~ ., data = .)
lm1 %>% broom::tidy() %>% 
  arrange(p.value)
lm1 %>% broom::glance()
# Not a bad model for pricing predictions, need to address VIF most likely

lm1 %>% vif() %>% as.data.frame() %>% 
  dplyr::rename(VIF = 1) %>% 
  arrange(desc(VIF))

corr_slice <- function(df_in, series_select){
df_in %>% 
  cor() %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "series") %>% 
  dplyr::filter(series == series_select) %>% 
  t() %>% 
  as.data.frame() %>% 
  rename(Correlation = 1) %>% 
  tail(-1) %>% 
  arrange(desc(Correlation)) %>% 
  tail(-1) %>% 
  return()
}

uninterpolated_data %>% corr_slice("Mining_Production_Index")
uninterpolated_data %>% corr_slice("US_Crude_Prod")

# Dropping Mining Production Index due to high VIF. Because it intersects highly with US_Crude_Prod, our next high VIF, we remodel and reassess.

uninterpolated_data %>% 
  dplyr::select(-Mining_Production_Index) %>% 
  lm(Crack_Spread ~ ., data = .) %>% 
  vif() %>% 
  as.data.frame() %>% 
  dplyr::rename(VIF = 1) %>% 
  arrange(desc(VIF))

# Crude Inventory is High, however it is a core market driver in our model, and has higher data frequency. As such, we will assess other factors and remove the ones with highest overlap.

uninterpolated_data %>% 
  dplyr::select(-Mining_Production_Index) %>% 
  corr_slice("US_Crude_Inventory")

# We notice here that the highest correlations are to gasoline stocks and petrol imports/exports. We should be okay to drop both of these, since blended gasoline stock is a more compressed portion of the market (smaller number compared to RBOB and Conventional blending formula) and we notice lower correlations in those categories.

# Net imports makes sense. As stocks rise, some companies may import gasoline/diesel to meet rushed demand if they are slightly behind in their refined product inventories, and thus we're better off simply keeping the Crude Inventory Level to reduce the VIF.

# Time to test VIF once more:
data_vif_adj <- uninterpolated_data %>% 
  dplyr::select(-Mining_Production_Index,
                -US_Gasoline_Stocks_Blended,
                -US_Petrol_Products_NI)

lm_vif_adjusted <- data_vif_adj %>% 
  lm(Crack_Spread ~ ., data = .)

lm_vif_adjusted %>% 
  vif() %>% 
  as.data.frame() %>% 
  dplyr::rename(VIF = 1) %>% 
  arrange(desc(VIF))
  
lm_vif_adjusted %>% broom::glance()
lm_vif_adjusted %>% broom::tidy() %>% 
  arrange(p.value)

# This model appears to be pretty decent for regressions assumptions. Normal Q-Q looks nice, some slight curvature in Residuals vs Fitted, but otherwise this model seems pretty valid.

lm_vif_adjusted %>% autoplot()
data_vif_adj$prediction <- lm_vif_adjusted %>% predict()

data_vif_adj %>% 
  dplyr::mutate(t = 1, t = cumsum(t)) %>% 
  dplyr::left_join(uninterpolated_data_w_date %>% dplyr::select(t,date), by = "t") %>% 
  dplyr::select(date, prediction, Crack_Spread) %>% 
  dplyr::rename(Prediction = prediction) %>% 
  pivot_longer(names_to = "Legend", cols = c("Prediction", "Crack_Spread")) %>% 
  ggplot(aes(color = Legend)) +
  geom_line(aes(x=date, y=value)) +
  geom_line(aes(x=date, y=value)) +
  labs(title = "Predicting Crack Spread with Fundamental Drivers",
       x = "Date",
       y = "Price",
       legend = "Legend")

```


## Recommendation

## Rationale

## Fundamental Market Drivers

Data was selected by a combination of higher correlations with the crack spread prices as well as higher data frequency supporting more timely decision making.

Demand Side:
-Truck Tonnage
-Billion Miles Driven

Supply Side:
-US Crude Inventory
-US Crude Production
-Percent Operable Utilization (Refineries)
-Gasoline Stocks, both RBOB and Conventional

Both Supply and Demand Side:
-Mining Production Index (dropped due to High VIF)

## Risk

Crack spread is more volatile than an outright position for a couple of reasons. Firstly, the crack spread is affected by 3 separate prices -- crude, gasoline and distillates. Secondly, the spread between the prices is nominally smaller than the prices themselves. Combined, this means an uncorrelated move in any of the 3 prices will often result in a proportionally larger move in the spread. This makes the spread more risky. This can be seen by comparing gasoline prices the crack spread prices below:

```{r}
#Graph Goes Here
```

## Appendix

### Development Notes

```{r, Developer Notes}
# A place for the developer to note potential features and future directions to take the model.

# Can today's crack spread be used to predict tomorrows crude price? Perhaps is the crack spread is favorable enough we can expect a bullish run on crude as companies seek to increase production to capitalize on higher margins.

# Note the move to v2 API call on EIA

# 3 potential options for modelling future price: 
  # Regression model, and STI forecasts of dependent variables.
  # Regression model making predictions using lagged variables.
  # Regression model that predicts today price, and the difference between the prediction and the actual       # price is used.
  #The third option can be improved with Jarque-Bera distribution on the error terms, to determine how "off" a particular day is.

# Option 3 is preferable, since it can give us a band of expected prices today, and help us get a better sense of a strong/weak reversal potential.
```
